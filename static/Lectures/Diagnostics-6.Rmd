---
title: "Assumptions"
author: Josh Jackson
date: "2-24-20"
output:
  xaringan::moon_reader:
    mathjax: "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML"
    lib_dir: libs
    css: xaringan-themer.css
    seal: false
    nature:
      highlightStyle: github
      highlightLines: true
      ratio: "16:9"
---

```{r xaringan-themer, include = FALSE}
library(xaringanthemer)
mono_light(
  base_color = "#23395b",
  header_font_google = google_font("Josefin Sans"),
  text_font_google   = google_font("Montserrat", "300", "300i"),
  code_font_google   = google_font("Droid Mono"),
)

library(tidyverse)
library(broom)
```

<style type="text/css">
.remark-slide-content {
    font-size: 30px;
    padding: 1em 4em 1em 4em;
}

.small .remark-code { 
  font-size: 80% !important;
}
.tiny .remark-code {
  font-size: 65% !important;
}
</style>

## This time/last time
Finished up multiple regression basics.

This time we will talk about the assumptions lurking in the background.

---
## We want to be BLUE
- Best linear unbiased estimate of beta  
<br> 
Properties: Unbiased, Efficient (se minimum), Consistent (N decreases se)

---

## 6 assumptions
1. No measurement error
2. Correctly specified form
3. No omitted variables
4. Homoscedasticity 
5. Independence among the residuals
6. Normally distributed residuals

---
## What happens if we violate assumptions?
1. Biased regression coefficients
2. Biased standard errors

---
## 6 assumptions

|Violated Regression Assumption |	Coefficients |	Standard Errors|
|-------------------------------|--------------|-----------------|
|1. Measured without error     	|	 Biased 		 |	  Biased       |
|2. Correctly specified form 		|	 Biased 		 |	  Biased       |
|3. Correctly specified model		|	 Biased			 |	  Biased       | 
|4. Homoscedasticity 						|				       |    Biased       |
|5. Independent Errors 				 	|				       |    Biased       |
|6. Normality of the Errors 		|							 |    Biased       |

---
## How do we detect violations? 
|       Assumption              |       	detect                    |
|-------------------------------|--------------------------------|
|1. Measured without error	    |	  Reliability                  |
|2. Correctly specified form 		|	  Residuals against predicted  |
|3. Correctly specified model		|	  Theory, endogeneity test     | 
|4. Homoscedasticity 						|		Residuals against predicted  |
|5. Independent Errors 				 	|		Design                       |
|6. Normality of the Errors     |   q-q plot or distribution     |

---
```{r, messages = FALSE, warning= FALSE}

library(readr)
a_data <- read.csv("diagnostics.csv")
library(broom)
model.1 <- lm(Anxiety ~ Stress + Support, a_data)
a_data<- augment(model.1)
a_data
```

---
## Residuals are very important 
They tell us where our model went wrong
```{r, echo = FALSE, warning=FALSE}

model.0 <- lm(Anxiety ~ Support , a_data)
a_data.0<- augment(model.0)

library(ggplot2)
ggplot(a_data.0, aes(x = Support, y = Anxiety)) +
  geom_smooth(method = "lm", se = FALSE, color = "lightgrey") +  # Plot regression slope
  geom_segment(aes(xend = Support, yend = .fitted), alpha = .2) +  # alpha to fade lines
  geom_point() +
  geom_point(aes(y = .fitted), shape = 1)
```

---
## With two predictors
Why does it look this way? 
```{r, echo = FALSE}

ggplot(a_data, aes(x = Support, y = Anxiety)) +
  geom_segment(aes(xend = Support, yend = .fitted), alpha = .2) +  # alpha to fade lines
  geom_point() +
  geom_point(aes(y = .fitted), shape = 1)
```


---
## Assumption 1: No measurement error in our independent variables


---
## Assumption 2: Correctly specified form

```{r, echo = FALSE, message = FALSE}
library(ggplot2)

ggplot(data = a_data, aes(x=.fitted, y=.resid)) + 
  geom_hline(yintercept = 0) +
  geom_point() + geom_smooth( se = FALSE)
```


---
## Assumption 3: Correctly specified model
- This is especially important for multiple regression. 
- Two problems: 
  1. "Over control" and your coefficient is no longer interpretable
  2. "Under control" and your coefficient is no longer interpretable

---
## Endogeneity 
.pull-left[
- Where your error term is associated with a predictor 
- Typically due to leaving out an important predictor

If this is the true model: 
$${Y_i} = b_{0} + b_{1}X_{1} + b_{2}X_{2} + \epsilon_i$$
But you only model 
$${Y_i} = b_{0} + b_{1}X_{1} + \epsilon_i$$
]

.pull-right[
The extra term is absorbed into the error so that
$${Y_i} = b_{0} + b_{1}X_{1} + (\epsilon_i +X_{2})$$
If $X_{1}$ and $X_{2}$ are correlated and $X_{2}$ is associated with ${Y_i}$ above and beyond $X_{1}$ then the residual and predictor in this model will be correlated   

$${Y_i} = b_{0} + b_{1}X_{1} + \epsilon_i$$
]
---
## Endogeneity
- Can also occur if you "condition on a collider". Many ways this can happen but one common one is selecting a sample (clinical students, college students) that are associated with your variables of interest (e.g., emotion regulation, memory ability)

- For example, there is a perceived negative association between methodological rigor and innovativeness in published articles. Is there actually a causal negative correlation? No, it is because both are associated with getting published. Controlling for one another introduces the incorrect negative association. 

- See Rohrer 2018 


---
## Assumption 4: Homoscedasticity

```{r, echo = FALSE, message=FALSE}
ggplot(data = a_data, aes(x=.fitted, y=.resid)) + geom_point() + 
    geom_hline(yintercept = 0) +
  geom_smooth(se = FALSE)

```


---
## Assumption 5: Independence among the errors

```{r, echo = FALSE}
a_data$ID <- c(1:118)
ggplot(data = a_data, aes(x=ID, y = .resid)) + geom_point() +  geom_hline(yintercept = 0) 

```

---
## Assumption 6: Normality of the errors
```{r, echo = FALSE}
ggplot(data = a_data, aes(x= .resid)) + geom_density() +   xlim(-10, 10)
```


---
```{r, echo = FALSE}
ggplot(model.1) +
  stat_qq(aes(sample = .stdresid)) +
  geom_abline()
```

---
## car package also works 
```{r}
library(car)
qqPlot(model.1)
#base plot function too
#plot(model.1, which = 2)
```


---
## How do we fix violations? 

|       Assumption              |       	Fix                      |
|-------------------------------|----------------------------------|
|1. Measured without error	    |	SEM, factor scores, more data, better design    |
|2. Correctly specified form 		|	Different model                  |
|3. Correctly specified model		|	 ¯\\__(ツ)_/¯  & specificity analyses|
|4. Homoscedasticity 						|	Bootstraps, WLS, transformations  |
|5. Independent Errors 				 	| Use differ analysis method                |
|6. Normality of the Errors     | Additional IVs, different form    |
---
## Robustness? 

- yeah, mostly
- especially with normally of errors
- note: we do not need to have normally distributed IVs or DVs

---
## Data screening

- Start with descriptive stats and plots   
- Look for outliers, missing cases, etc.  
- Test assumptions (residual plots)  

---
## Why screen your data? 

---
## Outliers
- Broadly defined as atypical or highly influential data point(s) 
- Due to contamination (e.g. recording error) or accurate observation of a rare case 
- Univariate vs. Multivariate 

---
## Outliers

1. Leverage   
    + How unusual is this case from the rest of the cases in terms of predictors?  
2. Distance   
    + How distant is the observed case from the predicted value?   
3. Influence   
    + How much the does regression coefficient change if case were removed? 
  
---
## Leverage

- Tells us how far observed values for a case are from mean values on the set of IVs (centroid)   
- Not dependent on Y values  
- High leverage cases have greater potential to influence regression results  
- Mahalanobis Distance for multivariate stats 

---
## Distance

- Distance From Prediction- how far is observed value from predicted value (i.e. residuals)   

- deleted residuals takes into consideration what would happen if case were deleted 


---
## Influence
- How regression equation would change if extreme case were removed 
- Influence = Leverage X Distance 
- DFFITS (difference in fit standardized)
- Cooks D (same but different metric to DFFITS)
- DFBETAS (coefficient change without outlier)


---
## cooks d
```{r, echo = FALSE}
ggplot(a_data, aes(x = ID, y = .cooksd)) +
geom_point() +
geom_text(aes(label = rownames(a_data)), vjust = -1)
```

---
## df beta
```{r, echo = FALSE}

a_data$dfbetastress <- dfbeta(model.1)[,"Stress"]

ggplot(data = a_data, aes(x = ID, y = dfbetastress)) + geom_point() +
geom_text(aes(label = rownames(a_data), vjust = -1))
```

---
## Recommendations
- Analyze data with/without outliers and see how results change   
- If you throw out cases you must believe it is not representative of population of interest or have appropriate explanation 
- Don't throw out data just to be "safe". Data are hard to collect and outliers are expected! 


